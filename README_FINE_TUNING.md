# ğŸš€ Fine-tuning Amazon Titles - Tech Challenge

Projeto completo de Fine-tuning de Foundation Models usando o dataset Amazon Titles (~2 milhÃµes de registros).

## ğŸ¯ Objetivo do Projeto

Implementar um pipeline completo de fine-tuning para modelos de linguagem usando dados de produtos da Amazon, demonstrando:

- **PreparaÃ§Ã£o de dados** em larga escala
- **Fine-tuning otimizado** com Unsloth
- **AvaliaÃ§Ã£o de performance** antes e depois
- **AnÃ¡lise exploratÃ³ria** completa dos dados

## ğŸ“Š Dataset

**Amazon Titles Dataset**
- **Arquivo**: `trn.json`
- **Tamanho**: ~2 milhÃµes de registros
- **Estrutura**: TÃ­tulos e descriÃ§Ãµes de produtos
- **Formato**: JSON

### Estrutura dos Dados
```json
{
  "title": "Nome do Produto",
  "description": "DescriÃ§Ã£o detalhada do produto"
}
```

## ğŸ—ï¸ Arquitetura do Projeto

```
fine_tuning_project/
â”œâ”€â”€ fine_tuning_project.py    # Pipeline principal
â”œâ”€â”€ data_analysis.py          # AnÃ¡lise exploratÃ³ria
â”œâ”€â”€ config.py                 # ConfiguraÃ§Ãµes
â”œâ”€â”€ requirements_fine_tuning.txt
â”œâ”€â”€ README_FINE_TUNING.md
â””â”€â”€ outputs/
    â”œâ”€â”€ fine_tuned_model/     # Modelo treinado
    â”œâ”€â”€ logs/                 # Logs de treinamento
    â”œâ”€â”€ plots/                # VisualizaÃ§Ãµes
    â””â”€â”€ reports/              # RelatÃ³rios
```

## ğŸš€ Como Executar

### 1. PreparaÃ§Ã£o do Ambiente

```bash
# Instalar dependÃªncias
pip install -r requirements_fine_tuning.txt

# Para GPU (recomendado)
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
```

### 2. AnÃ¡lise ExploratÃ³ria

```bash
# Executar anÃ¡lise dos dados
python data_analysis.py
```

**SaÃ­das**:
- `data_analysis_plots.png` - VisualizaÃ§Ãµes
- `wordcloud_titles.png` - Wordcloud dos tÃ­tulos
- `wordcloud_descriptions.png` - Wordcloud das descriÃ§Ãµes
- `data_analysis_report.json` - RelatÃ³rio completo

### 3. Fine-tuning

```bash
# Executar pipeline completo
python fine_tuning_project.py
```

**SaÃ­das**:
- `fine_tuned_model/` - Modelo treinado
- `test_results.json` - Resultados dos testes
- `fine_tuning.log` - Logs do processo

## ğŸ”§ ConfiguraÃ§Ãµes

### Modelo Base
- **Modelo**: `microsoft/DialoGPT-medium`
- **RazÃ£o**: Boa performance para geraÃ§Ã£o de texto
- **Alternativas**: `gpt2`, `EleutherAI/gpt-neo-125M`

### ParÃ¢metros de Treinamento
```python
MODEL_CONFIG = {
    "max_length": 512,
    "batch_size": 4,
    "learning_rate": 2e-5,
    "num_epochs": 3,
    "warmup_steps": 500
}
```

### OtimizaÃ§Ãµes
- **QuantizaÃ§Ã£o 4-bit**: Economia de memÃ³ria
- **Gradient Accumulation**: Simula batches maiores
- **Mixed Precision**: Acelera treinamento

## ğŸ“ˆ Fluxo de Trabalho

### 1. PreparaÃ§Ã£o de Dados
- âœ… Carregamento do JSON
- âœ… Limpeza (NAs, HTML, caracteres especiais)
- âœ… Filtros de qualidade
- âœ… CriaÃ§Ã£o de prompts

### 2. AnÃ¡lise ExploratÃ³ria
- âœ… EstatÃ­sticas bÃ¡sicas
- âœ… DistribuiÃ§Ã£o de comprimentos
- âœ… AnÃ¡lise de palavras frequentes
- âœ… RelatÃ³rio de qualidade

### 3. Fine-tuning
- âœ… Carregamento otimizado com Unsloth
- âœ… TokenizaÃ§Ã£o eficiente
- âœ… Treinamento com early stopping
- âœ… Salvamento de checkpoints

### 4. AvaliaÃ§Ã£o
- âœ… Teste do modelo base
- âœ… Teste do modelo fine-tunado
- âœ… ComparaÃ§Ã£o de resultados

## ğŸ¯ Conceitos TÃ©cnicos

### Fine-tuning vs RAG

| Aspecto | Fine-tuning | RAG |
|---------|-------------|-----|
| **Processo** | Retreinar modelo | Busca + GeraÃ§Ã£o |
| **Dados** | EstÃ¡ticos | DinÃ¢micos |
| **Performance** | Superior | Boa |
| **Complexidade** | Alta | Baixa |
| **Custo** | Alto | Baixo |

### Vantagens do Fine-tuning
- âœ… **Melhor qualidade** de geraÃ§Ã£o
- âœ… **ConsistÃªncia** com dados especÃ­ficos
- âœ… **Performance** otimizada
- âœ… **Menor latÃªncia** na inferÃªncia

### Vantagens do RAG
- âœ… **AtualizaÃ§Ã£o fÃ¡cil** dos dados
- âœ… **ImplementaÃ§Ã£o simples**
- âœ… **Menor custo** computacional
- âœ… **Flexibilidade** de dados

## ğŸ“Š MÃ©tricas de AvaliaÃ§Ã£o

### Antes do Fine-tuning
- Loss inicial
- Perplexidade
- Qualidade das respostas

### Depois do Fine-tuning
- Loss final
- Melhoria na perplexidade
- Qualidade das respostas especÃ­ficas

## ğŸ” AnÃ¡lise de Dados

### EstatÃ­sticas Esperadas
- **Total de registros**: ~2M
- **TÃ­tulos Ãºnicos**: ~80-90%
- **DescriÃ§Ãµes Ãºnicas**: ~70-80%
- **Comprimento mÃ©dio tÃ­tulo**: 50-100 caracteres
- **Comprimento mÃ©dio descriÃ§Ã£o**: 200-500 caracteres

### Limpeza Aplicada
- âœ… RemoÃ§Ã£o de HTML tags
- âœ… NormalizaÃ§Ã£o de espaÃ§os
- âœ… Filtro por comprimento mÃ­nimo
- âœ… RemoÃ§Ã£o de duplicatas

## ğŸ› ï¸ Dicas PrÃ¡ticas

### Performance
- **ComeÃ§ar com 100k registros** para teste
- **Aumentar gradualmente** se necessÃ¡rio
- **Monitorar uso de memÃ³ria**
- **Usar GPU** quando disponÃ­vel

### Qualidade dos Dados
- **Manter dados em inglÃªs** para melhor performance
- **NÃ£o reduzir abaixo de 100k** registros
- **Validar limpeza** antes do treinamento
- **Testar diferentes modelos** se necessÃ¡rio

### Treinamento
- **Curva de erro pode oscilar** (normal)
- **Early stopping** para evitar overfitting
- **Checkpoints regulares** para recuperaÃ§Ã£o
- **Monitoramento de mÃ©tricas** em tempo real

## ğŸ“ EntregÃ¡veis

### âœ… CÃ³digo Completo
- Pipeline de fine-tuning
- AnÃ¡lise exploratÃ³ria
- ConfiguraÃ§Ãµes otimizadas

### âœ… DocumentaÃ§Ã£o
- README detalhado
- ComentÃ¡rios no cÃ³digo
- RelatÃ³rios de anÃ¡lise

### âœ… Resultados
- Modelo fine-tunado
- MÃ©tricas de avaliaÃ§Ã£o
- ComparaÃ§Ãµes antes/depois

### âœ… VÃ­deo de DemonstraÃ§Ã£o
- ExplicaÃ§Ã£o do processo
- DemonstraÃ§Ã£o dos resultados
- AnÃ¡lise dos dados

## ğŸš€ PrÃ³ximos Passos

### Melhorias PossÃ­veis
- [ ] Testar diferentes modelos base
- [ ] Implementar RAG como comparaÃ§Ã£o
- [ ] Otimizar hiperparÃ¢metros
- [ ] Adicionar mais mÃ©tricas de avaliaÃ§Ã£o
- [ ] Interface web para demonstraÃ§Ã£o

### ExpansÃµes
- [ ] Dataset maior (todos os 2M registros)
- [ ] Modelos maiores (7B+ parÃ¢metros)
- [ ] Fine-tuning LoRA/QLoRA
- [ ] IntegraÃ§Ã£o com APIs

## ğŸ“š ReferÃªncias

- [Unsloth Documentation](https://github.com/unslothai/unsloth)
- [Hugging Face Transformers](https://huggingface.co/docs/transformers)
- [Amazon Product Data](https://jmcauley.ucsd.edu/data/amazon/)
- [Fine-tuning Best Practices](https://huggingface.co/docs/transformers/training)

---

**"The best model is the one that works for your specific use case."** ğŸ¤–

*Projeto desenvolvido para Tech Challenge - Fine-tuning de Foundation Models* 